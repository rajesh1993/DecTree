{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle as pkl\n",
    "import argparse\n",
    "import csv\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import time\n",
    "import pandas as pd\n",
    "from scipy.stats import chisquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(ftrain, ftest):\n",
    "    Xtrain, Ytrain, Xtest = [],[],[]\n",
    "    with open(ftrain, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            rw = [int(x) for x in row[0].split()]\n",
    "            Xtrain.append(rw)\n",
    "\n",
    "    with open(ftest, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            rw = [int(x) for x in row[0].split()]\n",
    "            Xtest.append(rw)\n",
    "\n",
    "    ftrain_label = ftrain.split('.')[0] + '_label.csv'\n",
    "    with open(ftrain_label, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            rw = int(row[0])\n",
    "            Ytrain.append(rw)\n",
    "    #Remove this block before submission and remove Ytest\n",
    "    Ytest = []\n",
    "    ftest_label = ftest.split('.')[0] + '_label.csv'\n",
    "    with open(ftest_label, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            rw = int(row[0])\n",
    "            Ytest.append(rw)\n",
    "\n",
    "    print('Data Loading: done')\n",
    "    return Xtrain, Ytrain, Xtest, Ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loading: done\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = load_data('train.csv', 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame(X_train)\n",
    "y_train = pd.DataFrame(Y_train)\n",
    "x_test = pd.DataFrame(X_test)\n",
    "y_test = pd.DataFrame(Y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.columns = ['Y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_train = pd.concat([x_train,y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infoGainOld(TD):\n",
    "    #Initialize gain parameters\n",
    "#     counts = TD['Y'].value_counts()\n",
    "#     sysEnt = scipy.stats.entropy([x/sum(counts) for x in counts], base = 2)\n",
    "    TD_length = len(TD)\n",
    "#     gain = []\n",
    "    min_gain = 99999\n",
    "    minGainColumn = -1\n",
    "    for column in TD:\n",
    "        #Ignoring output column\n",
    "        if column == 'Y':\n",
    "            continue\n",
    "        #Obtain the unique values in the column\n",
    "        #Initialize column entropy to zero\n",
    "        col_entropy = 0\n",
    "        for value in set(TD[column]):\n",
    "            #Obtain the output variable counts for one value in current column\n",
    "            Y_counts = TD.loc[TD[column].isin([value])]['Y'].value_counts()\n",
    "            sum_Y_counts = sum(Y_counts)\n",
    "            #Calculate entropy for that value in the column\n",
    "            #Add the entropy to the column entropy\n",
    "            col_entropy += (sum_Y_counts/TD_length) * scipy.stats.entropy([x/sum_Y_counts for x in Y_counts], base = 2)\n",
    "        #Compute column gain using system entropy\n",
    "#         col_gain = sysEnt - col_entropy\n",
    "#         gain.append(col_entropy)\n",
    "        #Find max gain\n",
    "        if col_entropy < min_gain:\n",
    "            min_gain = col_entropy\n",
    "            minGainColumn = column\n",
    "    #Return the column having maximum gain\n",
    "#     np_gain = np.array(gain[:-1])\n",
    "    return minGainColumn\n",
    "#     return np.argmin(np_gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CLASS\n",
    "class TreeNode():\n",
    "    def __init__(self, data='T',children=[-1]*5):\n",
    "        self.nodes = list(children)\n",
    "        self.data = data\n",
    "\n",
    "\n",
    "    def save_tree(self,filename):\n",
    "        obj = open(filename,'w')\n",
    "        pkl.dump(self,obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ID3Algo(T, node, depth, best_attrib):\n",
    "#     print(depth)\n",
    "    Y_counts = T['Y'].value_counts()\n",
    "    if depth == 0:\n",
    "        if Y_counts[1] > Y_counts[0]:\n",
    "            return TreeNode('T', [])\n",
    "        else:\n",
    "            return TreeNode('F', [])\n",
    "#     best_attrib = infoGainOld(T)\n",
    "#     if best_attrib == -1:\n",
    "#         if Y_counts.index[0] == 1:\n",
    "#             return TreeNode('T', [])\n",
    "#         else:\n",
    "#             return TreeNode('F', [])\n",
    "    node.data = best_attrib\n",
    "    children = []\n",
    "    child_attrib = {}\n",
    "    cols = set(T.columns)\n",
    "    cols.remove(best_attrib)\n",
    "    for value in set(T[best_attrib]):\n",
    "        splitData = T.loc[T[best_attrib].isin([value]), cols]\n",
    "#         splitData = splitData.drop([best_attrib], axis = 1)\n",
    "        splitCounts = splitData['Y'].value_counts()\n",
    "        if len(splitCounts) == 1:\n",
    "            if splitCounts.index[0] == 1:\n",
    "                child = TreeNode('T',[])\n",
    "            else:\n",
    "                child = TreeNode('F',[])\n",
    "        else:\n",
    "            best_attrib_child = infoGainOld(splitData)\n",
    "            if str(best_attrib_child) in child_attrib:\n",
    "                child = child_attrib[str(best_attrib_child)]\n",
    "            else:\n",
    "                child = ID3Algo(splitData, TreeNode(), depth-1, best_attrib_child)\n",
    "                child_attrib[str(best_attrib_child)] = child\n",
    "        children.append((value, child))\n",
    "    node.nodes = children\n",
    "    return node\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ID3AlgoNew(T, node, depth, best_attrib):\n",
    "#     print(depth)\n",
    "    Y_counts = T['Y'].value_counts()\n",
    "    #Depth-limiter\n",
    "    if depth == 0:\n",
    "        if Y_counts[1] > Y_counts[0]:\n",
    "            return TreeNode('T', [])\n",
    "        else:\n",
    "            return TreeNode('F', [])\n",
    "    #Pure subset\n",
    "    if len(Y_counts) == 1:\n",
    "        if Y_counts.index[0] == 1:\n",
    "            return TreeNode('T',[])\n",
    "        else:\n",
    "            return TreeNode('F',[])\n",
    "    #Store best attribute in current node's data\n",
    "    node.data = best_attrib\n",
    "    children = []\n",
    "    child_attrib = {}\n",
    "    cols = set(T.columns)\n",
    "    cols.remove(best_attrib)\n",
    "    for value in set(T[best_attrib]):\n",
    "        #Split the data by each value in best_attrib\n",
    "        splitData = T.loc[T[best_attrib].isin([value]), cols]\n",
    "        #Compute best attrib for the child split\n",
    "        best_attrib_child = infoGainOld(splitData)\n",
    "        #Check if the child tree has already been computed\n",
    "        if str(best_attrib_child) in child_attrib:\n",
    "            child = child_attrib[str(best_attrib_child)]\n",
    "        else:\n",
    "            #Compute child recursively\n",
    "            child = ID3Algo(splitData, TreeNode(), depth-1, best_attrib_child)\n",
    "            child_attrib[str(best_attrib_child)] = child\n",
    "        #Store all children in an array\n",
    "        children.append((value, child))\n",
    "    #Set current node's children to the list of children\n",
    "    node.nodes = children\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105.66080904006958\n"
     ]
    }
   ],
   "source": [
    "root = TreeNode()\n",
    "A= time.time()\n",
    "root_tree = ID3AlgoNew(XY_train,root, 4, 89)\n",
    "print(time.time() - A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 271\n",
      "2 167\n",
      "3 268\n",
      "4 80\n",
      "5 271\n"
     ]
    }
   ],
   "source": [
    "for value, feature in root_tree.nodes:\n",
    "    print(value, feature.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "National\n",
      "col_0      count\n",
      "0               \n",
      "asian      15000\n",
      "black      50000\n",
      "hispanic   60000\n",
      "other      35000\n",
      "white     100000\n",
      " \n",
      "Minnesota\n",
      "col_0     count\n",
      "0              \n",
      "asian        75\n",
      "black       250\n",
      "hispanic    300\n",
      "other       150\n",
      "white       600\n"
     ]
    }
   ],
   "source": [
    "national = pd.DataFrame([\"white\"]*100000 + [\"hispanic\"]*60000 +\\\n",
    "                        [\"black\"]*50000 + [\"asian\"]*15000 + [\"other\"]*35000)\n",
    "           \n",
    "\n",
    "minnesota = pd.DataFrame([\"white\"]*600 + [\"hispanic\"]*300 + \\\n",
    "                         [\"black\"]*250 +[\"asian\"]*75 + [\"other\"]*150)\n",
    "\n",
    "national_table = pd.crosstab(index=national[0], columns=\"count\")\n",
    "minnesota_table = pd.crosstab(index=minnesota[0], columns=\"count\")\n",
    "\n",
    "print( \"National\")\n",
    "print(national_table)\n",
    "print(\" \")\n",
    "print( \"Minnesota\")\n",
    "print(minnesota_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508.1455432407473\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# observed = minnesota_table\n",
    "observed = y_test[0].value_counts()\n",
    "# national_ratios = national_table/len(national)  # Get population ratios\n",
    "\n",
    "# expected = national_ratios * len(minnesota)   # Get expected counts\n",
    "expected = y_train['Y'].value_counts()/len(y_train) * len(y_test)\n",
    "chi_squared_stat = (((observed-expected)**2)/expected).sum()\n",
    "\n",
    "print(chi_squared_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=508.14554324074732, pvalue=1.6058049173024654e-112)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.chisquare(observed,expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07659220695495605\n",
      "211.429588953\n"
     ]
    }
   ],
   "source": [
    "B = time.time()\n",
    "T= XY_train\n",
    "best_attrib = 1\n",
    "chis = 0\n",
    "for value in set(T[best_attrib]):\n",
    "    splitData = T.loc[T[best_attrib].isin([value])]\n",
    "    splitData = splitData.drop([best_attrib], axis = 1)\n",
    "    observed = splitData['Y'].value_counts()\n",
    "    expected = T['Y'].value_counts() / len(T) * len(splitData)\n",
    "    S, p = scipy.stats.chisquare(observed,expected)\n",
    "    chis += S\n",
    "#     print(value, scipy.stats.chisquare(observed,expected))\n",
    "print(time.time() - B)\n",
    "print(chis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = scipy.stats.chi2.ppf(q = 0.95, # Find the critical value for 95% confidence*\n",
    "                      df = 4)   # Df = number of variable categories - 1\n",
    "\n",
    "print(\"Critical value\")\n",
    "print(crit)\n",
    "\n",
    "p_value = 1 - scipy.stats.chi2.cdf(x=20,  # Find the p-value\n",
    "                             df=4)\n",
    "print(\"P value\")\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infoGainOld(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
